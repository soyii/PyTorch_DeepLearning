{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1RZ5IuXZCak"
   },
   "source": [
    "# Music_speech_classifier_with_linear_network_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "himofQeMPW8O"
   },
   "source": [
    "#### 1. Music/speech classification. Try various efforts with linear feed-forward network. Achieve an accuracy above 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of network layers = 4 \n",
    "\n",
    "Tanh/LogSoftmax, NLLLoss\n",
    "\n",
    "learning rate = 0.01\n",
    "\n",
    "SGD\n",
    "\n",
    "Val accuracy = 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65qKJbknL-VJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize']=(15,3.4)\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3QnIULVOqh4"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (14, 3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20192,
     "status": "ok",
     "timestamp": 1587646309457,
     "user": {
      "displayName": "Soyi Kang",
      "photoUrl": "",
      "userId": "15788679644059944980"
     },
     "user_tz": -540
    },
    "id": "CVbP-7H3PRnK",
    "outputId": "0c78076b-6b22-4e75-fda9-5b3727156b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6kwpnikPR56"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class_names = ['music', 'speech']\n",
    "data_dir = {'music' : '/gdrive/My Drive/SGU_DeepLearning/music_speech/music_speech/music_wav', \n",
    "            'speech': '/gdrive/My Drive/SGU_DeepLearning/music_speech/music_speech/speech_wav'}\n",
    "\n",
    "wav_files = {cls_name: [] for cls_name in class_names}\n",
    "for cls_name in class_names:\n",
    "    folder = data_dir[cls_name]\n",
    "    filelist = os.listdir(folder)\n",
    "    for filename in filelist:\n",
    "        if filename[-4:] == '.wav':\n",
    "            wav_files[cls_name].append(os.path.join(folder, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nv_uVCn9PSB9"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "file_list = {'train': [], 'val': []}\n",
    "for class_id, c in enumerate(class_names):\n",
    "    n_data = len(wav_files[c])\n",
    "    rindx = np.random.permutation(n_data)\n",
    "    n_validation = int(0.25*n_data)\n",
    "    v_indx = rindx[:n_validation]\n",
    "    t_indx = rindx[n_validation:]\n",
    "    file_list['train'] += [ (wav_files[c][k], class_id) for k in t_indx ] \n",
    "    file_list['val'] += [ (wav_files[c][k], class_id) for k in v_indx ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3BXQxU2PR1V"
   },
   "outputs": [],
   "source": [
    "class MSDataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Music/Speech Classification \n",
    "        filelist: [(file_path, class_id)]\n",
    "        sample_time: time duration to sample from .wav file\n",
    "                     the sample is extracted somewhere in the middle of the whole sequence\n",
    "                     similar to data augmentation\n",
    "                     \n",
    "         Validation dataset: the first segment of the sequence is used.\n",
    "                             Another option is to apply several segments and accumulate multiple inferences\n",
    "    \"\"\"\n",
    "    def __init__(self, filelist, sample_sec=1., is_train=True):\n",
    "        self.filelist = filelist\n",
    "        self.time_duration = sample_sec\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        _, sf = self.load(filelist[0][0])\n",
    "        self.sf = sf\n",
    "        self.n_features = int(self.time_duration * sf)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # 1. load the file\n",
    "        # 2. sample a segment of the length from the whole seq\n",
    "        # 3. return segment, id\n",
    "        audio_file, class_id = self.filelist[i]\n",
    "        x, sf = librosa.load(audio_file)\n",
    "\n",
    "        if self.is_train:\n",
    "            k = np.random.randint(low=0, high=x.shape[0]-self.n_features) # choose the start index\n",
    "        else:\n",
    "            k = 0\n",
    "        \n",
    "        x = torch.from_numpy(x[k:k+self.n_features])\n",
    "        \n",
    "        # print('MSDataset(): ', x.shape)\n",
    "        assert x.shape[0] == self.n_features\n",
    "        \n",
    "        return x, class_id\n",
    "    \n",
    "    def load(self, audio_file):\n",
    "        return librosa.load(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3210,
     "status": "ok",
     "timestamp": 1587646359733,
     "user": {
      "displayName": "Soyi Kang",
      "photoUrl": "",
      "userId": "15788679644059944980"
     },
     "user_tz": -540
    },
    "id": "zFMFFm_OrMa7",
    "outputId": "6cbda5c0-fad9-4d50-cfe9-79d866a1a904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f6916611400>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7f6916e31be0>}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sec = 1.5\n",
    "batch_size = 2\n",
    "\n",
    "data_loader = {tv: \n",
    "                   torch.utils.data.DataLoader(\n",
    "                       MSDataset(file_list[tv], sample_sec=sample_sec, is_train=tv=='train'),\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                   )\n",
    "               for tv in ['train', 'val']}\n",
    "#\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6zQo_iSGNsq"
   },
   "outputs": [],
   "source": [
    "def myNetworkModel(in_features, n_targets):\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(in_features=in_features, out_features=1024),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(in_features=1024, out_features=256),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(in_features=256, out_features=256),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(in_features=256, out_features=n_targets),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print(f'myNetworkModel()  in: {in_features}  out: {n_targets}', 'n_params (K): ', pytorch_total_params/1000)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3136,
     "status": "ok",
     "timestamp": 1587646487606,
     "user": {
      "displayName": "Soyi Kang",
      "photoUrl": "",
      "userId": "15788679644059944980"
     },
     "user_tz": -540
    },
    "id": "RGoqRfxOGrUW",
    "outputId": "25ca8fb6-f3b0-44f7-a666-cb1554c457d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNetworkModel()  in: 33075  out: 2 n_params (K):  34198.53\n"
     ]
    }
   ],
   "source": [
    "n_features = data_loader['train'].dataset.n_features\n",
    "n_targets = 2\n",
    "\n",
    "model = myNetworkModel(n_features, n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnSPLtywGs7b"
   },
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optim, model, loss_fn, dl_train, dl_val, hist=None):\n",
    "    if hist is not None:\n",
    "        pass\n",
    "    else:\n",
    "        hist = {'tloss': [], 'tacc': [], 'vloss': [], 'vacc': []}\n",
    "    best_acc = 0\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        tr_loss, tr_acc = 0., 0.\n",
    "        n_data = 0\n",
    "        for im_batch, label_batch in dl_train: # minibatch\n",
    "            ypred = model(im_batch)\n",
    "            loss_train = loss_fn(ypred, label_batch)\n",
    "        \n",
    "            optim.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optim.step()\n",
    "   \n",
    "            # accumulate correct prediction\n",
    "            tr_acc  += (torch.argmax(ypred.detach(), dim=1) == label_batch).sum().item() # number of correct predictions\n",
    "            tr_loss += loss_train.item() * im_batch.shape[0]\n",
    "            n_data  += im_batch.shape[0]\n",
    "        #\n",
    "        # statistics\n",
    "        tr_loss /= n_data\n",
    "        tr_acc  /= n_data\n",
    "        #\n",
    "        val_loss, val_acc = performance(model, loss_fn, dl_val)\n",
    "        \n",
    "        if epoch <= 5 or epoch % 1000 == 0 or epoch == n_epochs:\n",
    "             print(f'Epoch {epoch}, tloss {tr_loss:.2f} t_acc: {tr_acc:.2f}  vloss {val_loss:.2f}  v_acc: {val_acc:.2f}')\n",
    "        else:\n",
    "            if best_acc < val_acc:\n",
    "                best_acc = val_acc\n",
    "                print(' best val accuracy updated: ', best_acc)\n",
    "        #\n",
    "        # record for history return\n",
    "        hist['tloss'].append(tr_loss)\n",
    "        hist['vloss'].append(val_loss) \n",
    "        hist['tacc'].append(tr_acc)\n",
    "        hist['vacc'].append(val_acc)\n",
    "        \n",
    "    print ('finished training_loop().')\n",
    "    return hist\n",
    "#\n",
    "\n",
    "def performance(model, loss_fn, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss, acc, n = 0., 0., 0.\n",
    "        for x, y in dataloader:\n",
    "            ypred = model(x)\n",
    "            loss += loss_fn(ypred, y).item() * len(y)\n",
    "            p = torch.argmax(ypred, dim=1)\n",
    "            acc += (p == y).sum().item()\n",
    "            n += len(y)\n",
    "        #\n",
    "    loss /= n\n",
    "    acc /= n\n",
    "    return loss, acc\n",
    "#\n",
    "def plot_history(history):\n",
    "    fig, axes = plt.subplots(1,2, figsize=(16,6))\n",
    "    axes[0].set_title('Loss'); \n",
    "    axes[0].plot(history['tloss'], label='train'); axes[0].plot(history['vloss'], label='val')\n",
    "    axes[0].legend()\n",
    "    max_vacc = max(history['vacc'])\n",
    "    axes[1].set_title(f'Acc. vbest: {max_vacc:.2f}')\n",
    "    axes[1].plot(history['tacc'], label='train'); axes[1].plot(history['vacc'], label='val')\n",
    "    axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3347,
     "status": "ok",
     "timestamp": 1587646539605,
     "user": {
      "displayName": "Soyi Kang",
      "photoUrl": "",
      "userId": "15788679644059944980"
     },
     "user_tz": -540
    },
    "id": "E_uqJZQbGxZM",
    "outputId": "7c94188a-61fe-440a-a240-d51c625a9410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNetworkModel()  in: 33075  out: 2 n_params (K):  34198.53\n"
     ]
    }
   ],
   "source": [
    "n_features = data_loader['train'].dataset.n_features\n",
    "n_targets = 2\n",
    "model = myNetworkModel(n_features, n_targets)\n",
    "\n",
    "# optim\n",
    "learning_rate = 0.01\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# history\n",
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "u2127yhAG3zJ",
    "outputId": "3110a1e6-693b-4d24-ab01-bd8af6404002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, tloss 0.69 t_acc: 0.51  vloss 0.70  v_acc: 0.50\n",
      "Epoch 2, tloss 0.70 t_acc: 0.49  vloss 0.69  v_acc: 0.50\n",
      "Epoch 3, tloss 0.69 t_acc: 0.48  vloss 0.69  v_acc: 0.66\n",
      "Epoch 4, tloss 0.69 t_acc: 0.55  vloss 0.69  v_acc: 0.62\n",
      "Epoch 5, tloss 0.69 t_acc: 0.53  vloss 0.69  v_acc: 0.66\n",
      " best val accuracy updated:  0.65625\n",
      " best val accuracy updated:  0.71875\n",
      " best val accuracy updated:  0.75\n",
      " best val accuracy updated:  0.78125\n",
      " best val accuracy updated:  0.8125\n"
     ]
    }
   ],
   "source": [
    "history = training_loop(500, optimizer, model, criterion, data_loader['train'], data_loader['val'], history)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbyCTMU8G83o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPbT2zCt4JgtZLRGt4TzLCw",
   "collapsed_sections": [],
   "name": "hw5_강소이_E192DBG03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
